{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8849b4a3-0f7a-4a5d-a639-874c3e35724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3fa8c6-0c34-480e-b7ce-eaac96ef2687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Conv Module\n",
    "def conv_module(x, filters, kernel_size, stride):\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b399e422-9027-4204-a8fa-149728bb4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Inception Module\n",
    "def inception_module(x, ch1_filters, ch3_filters):\n",
    "    branch1x1 = layers.Conv2D(ch1_filters, (1, 1), padding='same')(x)\n",
    "\n",
    "    branch3x3 = layers.Conv2D(ch3_filters, (3, 3), padding='same')(x)\n",
    "\n",
    "    x = layers.concatenate([branch1x1, branch3x3], axis=-1)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b515f901-40e0-4f0d-9405-aab9758d2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Downsample Module\n",
    "def downsample_module(x, filters, stride):\n",
    "    x = layers.Conv2D(filters, (3, 3), strides=stride, padding='same')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cfef0ad-2bff-4e6b-a346-289165912642",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = 128\n",
    "input_width = 128\n",
    "input_channels = 3 \n",
    "\n",
    "num_modules = 3\n",
    "conv_filters = 64\n",
    "conv_kernel_size = (3, 3)\n",
    "conv_stride = (1, 1)\n",
    "\n",
    "inception_ch1_filters = 32\n",
    "inception_ch3_filters = 32\n",
    "\n",
    "downsample_filters = 128\n",
    "downsample_stride = (2, 2)\n",
    "\n",
    "output_channels = 10 \n",
    "\n",
    "# Input layer\n",
    "input_layer = layers.Input(shape=(input_height, input_width, input_channels))\n",
    "x = input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8665302-8a29-4f98-94dd-fdaf231e8dfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 128, 128, 64), (None, 32, 32, 128)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m x_downsample \u001b[38;5;241m=\u001b[39m downsample_module(x_conv, downsample_filters, downsample_stride)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Concatenate outputs\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_inception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_downsample\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\merging\\concatenate.py:231\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.layers.concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate\u001b[39m(inputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Functional interface to the `Concatenate` layer.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    >>> x = np.arange(20).reshape(2, 2, 5)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m        A tensor, the concatenation of the inputs alongside axis `axis`.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\merging\\concatenate.py:131\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    125\u001b[0m unique_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[0;32m    126\u001b[0m     shape[axis]\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m shape_set\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shape[axis] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    129\u001b[0m )\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dims) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 128, 128, 64), (None, 32, 32, 128)]"
     ]
    }
   ],
   "source": [
    "# Build the architecture\n",
    "for _ in range(num_modules):  # Specify the desired number of modules\n",
    "    # Conv Module\n",
    "    x_conv = conv_module(x, conv_filters, conv_kernel_size, conv_stride)\n",
    "\n",
    "    # Inception Module\n",
    "    x_inception = inception_module(x_conv, inception_ch1_filters, inception_ch3_filters)\n",
    "\n",
    "    # Downsample Module\n",
    "    x_downsample = downsample_module(x_conv, downsample_filters, downsample_stride)\n",
    "\n",
    "    # Concatenate outputs\n",
    "    x = layers.concatenate([x_inception, x_downsample], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b27e22-0251-4309-a956-84958001fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Conv Module after concatenation\n",
    "x = conv_module(x, conv_filters, conv_kernel_size, conv_stride)\n",
    "\n",
    "# Additional Batch Norm layer\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "# Additional ReLU activation\n",
    "x = layers.Activation('relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dedcfa-74eb-453e-86bc-89b5a4fff646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer (adjust filters and kernel_size based on your task)\n",
    "output_layer = layers.Conv2D(output_channels, (1, 1), padding='same', activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d71f6f-4809-4eb3-a5c4-7fdc7dd6f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
